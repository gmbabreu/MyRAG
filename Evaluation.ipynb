{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40565603-c2d6-4187-956c-20b6d50e3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e266925-4a99-4725-b44e-c4001088a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [00:20, 17.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_html(raw_html):\n",
    "    \"\"\"Remove HTML tags from a string using BeautifulSoup.\"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def load_nq_data_gz(filepath):\n",
    "    \"\"\"Load the Natural Questions dataset from a gzipped JSONL file and extract questions, long answers, and documents.\"\"\"\n",
    "    data = []\n",
    "    i=0\n",
    "    count=0\n",
    "    \n",
    "    with gzip.open(filepath, 'rt', encoding='utf-8') as f:  # 'rt' mode for reading text\n",
    "        for line in tqdm(f):\n",
    "            entry = json.loads(line)\n",
    "            #print(entry)\n",
    "            question = entry[\"question_text\"]\n",
    "            document_text = entry[\"document_text\"]\n",
    "            annotations = entry.get(\"annotations\", [])\n",
    "            long_answer_text = None\n",
    "            short_answers = []\n",
    "            \n",
    "            # Extract long answer from token spans\n",
    "            if annotations:\n",
    "                long_answer = annotations[0].get(\"long_answer\", {})\n",
    "                start_idx, end_idx = long_answer.get(\"start_token\"), long_answer.get(\"end_token\")\n",
    "                \n",
    "                if start_idx is not None and end_idx is not None:\n",
    "                    tokenized_text = document_text.split()  # Basic tokenization\n",
    "                    long_answer_text = \" \".join(tokenized_text[start_idx:end_idx])\n",
    "            \n",
    "            # Extract short answers\n",
    "            if annotations and \"short_answers\" in annotations[0]:\n",
    "                short_answers = [\n",
    "                    \" \".join(document_text.split()[ans[\"start_token\"]:ans[\"end_token\"]])\n",
    "                    for ans in annotations[0][\"short_answers\"]\n",
    "                ]\n",
    "\n",
    "            # Ignore entries without a long answer\n",
    "            if long_answer_text:\n",
    "                data.append({\n",
    "                    \"question\": question,\n",
    "                    \"long_answer\": clean_html(long_answer_text),\n",
    "                    \"document_text\": clean_html(document_text)\n",
    "                })\n",
    "                i+=1\n",
    "                if i==200:break\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load dataset from gzipped file\n",
    "file_path = \"v1.0-simplified_simplified-nq-train.jsonl.gz\"\n",
    "nq_data = load_nq_data_gz(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1e4930b-74ab-468b-b88f-76c1abf082a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|█████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 617.25it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_chunks_and_map_questions(documents, chunk_size=2024, chunk_overlap=200):\n",
    "    \"\"\"Splits documents into chunks and maps questions to relevant chunks simultaneously, avoiding duplicate documents.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\\n\", \"\\n\\n\", \"\\n\",  \".\"],\n",
    "        add_start_index=True\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    question_chunk_map = []\n",
    "    chunk_indices = {}\n",
    "    seen_documents = set()\n",
    "    \n",
    "    for doc_idx, doc in enumerate(tqdm(documents, desc=\"Processing documents\")):\n",
    "        doc_text = doc[\"document_text\"]\n",
    "        \n",
    "        if doc_text in seen_documents:\n",
    "            # If the document is already processed, only map the question\n",
    "            question = doc['question']\n",
    "            long_answer = doc['long_answer']\n",
    "            for chunk_idx, chunk in chunk_indices.items():\n",
    "                if long_answer in chunk:\n",
    "                    question_chunk_map.append({\n",
    "                        \"question\": question,\n",
    "                        \"chunk\": chunk_idx\n",
    "                    })\n",
    "            continue\n",
    "        \n",
    "        seen_documents.add(doc_text)\n",
    "        chunks = text_splitter.split_text(doc_text)\n",
    "        start_index = len(all_chunks)  # Track the starting index of the new chunks\n",
    "        temp_chunks = []\n",
    "        temp_indices = {}\n",
    "        \n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            temp_chunks.append(chunk)\n",
    "            temp_indices[start_index + idx] = chunk  # Store temporarily\n",
    "        \n",
    "        question = doc['question']\n",
    "        long_answer = doc['long_answer']\n",
    "        found = any(long_answer in chunk for chunk in temp_chunks)\n",
    "        \n",
    "        if found:\n",
    "            all_chunks.extend(temp_chunks)\n",
    "            chunk_indices.update(temp_indices)\n",
    "            for chunk_idx, chunk in temp_indices.items():\n",
    "                if long_answer in chunk:\n",
    "                    question_chunk_map.append({\n",
    "                        \"question\": question,\n",
    "                        \"chunk\": chunk_idx\n",
    "                    })\n",
    "    \n",
    "    return all_chunks, question_chunk_map\n",
    "\n",
    "# Example usage\n",
    "chunks, question_map = create_chunks_and_map_questions(nq_data[:139])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a8e3020-13a8-477e-9862-87c8e825b529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccb7c1d3-242b-4adb-9567-d1305c733c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534a940-a111-404d-9069-f3683e047854",
   "metadata": {},
   "source": [
    "Graph Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aa8f0c6-e0f5-40cd-a062-05ef55fea51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2090/2090 [19:28:50<00:00, 33.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize embedding model\n",
    "EMBEDDING_MODEL = OllamaEmbeddings(\n",
    "    model=\"mxbai-embed-large\",\n",
    "    base_url=\"http://127.0.0.1:11434\"\n",
    ")\n",
    "\n",
    "# Initialize in-memory vector store\n",
    "DOCUMENT_VECTOR_DB = InMemoryVectorStore(EMBEDDING_MODEL)\n",
    "\n",
    "# Convert each chunk into a Document object\n",
    "for i in tqdm(range(len(chunks))):\n",
    "    doc = [Document(page_content=chunks[i], metadata={\"source\": f\"chunk{i}\"})]\n",
    "    \n",
    "    # Add documents to vector database\n",
    "    DOCUMENT_VECTOR_DB.add_documents(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1308c8d-7a7a-4538-9db9-2446e42314e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2090it [3:02:08,  5.23s/it] \n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "from MiniGraph import MiniRAGGraph\n",
    "\n",
    "rag_graph = MiniRAGGraph(similarity_threshold=0.8)\n",
    "\n",
    "# Construct Graph\n",
    "rag_graph.construct_graph(chunks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "239b27f9-0fd1-424f-8c96-43752188a0b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrag_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MyRAG\\Graph\\MiniGraph.py:206\u001b[0m, in \u001b[0;36mMiniRAGGraph.visualize_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m    205\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m10\u001b[39m))  \u001b[38;5;66;03m# Increase figure size\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspring_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust k for more spacing\u001b[39;00m\n\u001b[0;32m    208\u001b[0m entity_nodes \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes[n]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    209\u001b[0m chunk_nodes \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes[n]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Desktop\\MyRAG\\minirag_env\\Lib\\site-packages\\networkx\\utils\\decorators.py:788\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 4:4\u001b[0m, in \u001b[0;36margmap_spring_layout_1\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MyRAG\\minirag_env\\Lib\\site-packages\\networkx\\drawing\\layout.py:486\u001b[0m, in \u001b[0;36mspring_layout\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m    484\u001b[0m         nnodes, _ \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    485\u001b[0m         k \u001b[38;5;241m=\u001b[39m dom_size \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(nnodes)\n\u001b[1;32m--> 486\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43m_sparse_fruchterman_reingold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m     A \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mto_numpy_array(G, weight\u001b[38;5;241m=\u001b[39mweight)\n",
      "File \u001b[1;32m~\\Desktop\\MyRAG\\minirag_env\\Lib\\site-packages\\networkx\\utils\\decorators.py:788\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 12:4\u001b[0m, in \u001b[0;36margmap__sparse_fruchterman_reingold_9\u001b[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\MyRAG\\minirag_env\\Lib\\site-packages\\networkx\\drawing\\layout.py:621\u001b[0m, in \u001b[0;36m_sparse_fruchterman_reingold\u001b[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[0;32m    619\u001b[0m delta \u001b[38;5;241m=\u001b[39m (pos[i] \u001b[38;5;241m-\u001b[39m pos)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    620\u001b[0m \u001b[38;5;66;03m# distance between points\u001b[39;00m\n\u001b[1;32m--> 621\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# enforce minimum distance of 0.01\u001b[39;00m\n\u001b[0;32m    623\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(distance \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, distance)\n",
      "File \u001b[1;32m~\\Desktop\\MyRAG\\minirag_env\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rag_graph.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85a41d06-caf0-4c6a-afe0-224b6e61b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = DOCUMENT_VECTOR_DB.search(\"which is the most common use of opt-in e-mail marketing\", search_type=\"similarity\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25f3efda-2d87-4eaa-9ec1-1edd8d227d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.84 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = rag_graph.retrieve(\"which is the most common use of opt-in e-mail marketing\", top_k=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b572db3d-f0d0-4911-a015-dd86c8c267ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(chunk_ids, k=5):\n",
    "    \"\"\"Evaluate Recall@k for document retrieval.\"\"\"\n",
    "    total = 0\n",
    "    retrieved_correct = 0\n",
    "\n",
    "    for i in range(len(question_map)):\n",
    "        ground_truth = question_map[i][\"chunk\"]\n",
    "        chunk_id = chunk_ids[i]\n",
    "        if ground_truth and ground_truth in chunk_id:\n",
    "            retrieved_correct += 1\n",
    "        total += 1\n",
    "\n",
    "    recall_k = retrieved_correct / total if total > 0 else 0\n",
    "    return recall_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c28475b5-8fef-4599-84e1-0747fec6c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_vec = [DOCUMENT_VECTOR_DB.search(entry[\"question\"], search_type=\"similarity\", k=20) for entry in question_map]\n",
    "retreived_graph = [rag_graph.retrieve(entry[\"question\"], top_k=20) for entry in question_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e13452a7-9e6e-4284-a2b2-deac8f0102a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[\"chunk_id\"] for doc in retreived_graph[0]][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e882d32-810c-42a0-9a70-1056dfcccc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1, recall= 0.43\n",
      "k= 2, recall= 0.56\n",
      "k= 3, recall= 0.65\n",
      "k= 4, recall= 0.7\n",
      "k= 5, recall= 0.71\n",
      "k= 6, recall= 0.75\n",
      "k= 7, recall= 0.75\n",
      "k= 8, recall= 0.79\n",
      "k= 9, recall= 0.81\n",
      "k= 10, recall= 0.82\n",
      "k= 11, recall= 0.82\n",
      "k= 12, recall= 0.83\n",
      "k= 13, recall= 0.85\n",
      "k= 14, recall= 0.86\n",
      "k= 15, recall= 0.87\n",
      "k= 16, recall= 0.89\n",
      "k= 17, recall= 0.89\n",
      "k= 18, recall= 0.9\n",
      "k= 19, recall= 0.9\n",
      "k= 20, recall= 0.9\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 21):\n",
    "    vec_k_ids = []\n",
    "    graph_k_ids = []\n",
    "    # Select k ids\n",
    "    for i in range(len(retrieved_vec)):\n",
    "        vec_k_ids.append([int(doc.metadata[\"source\"][5:]) for doc in retrieved_vec[i]][:k])\n",
    "        graph_k_ids.append([doc[\"chunk_id\"] for doc in retreived_graph[i]][:k])\n",
    "    \n",
    "    #print(\"k:\", k)\n",
    "    #print(\"vector:\", recall(vec_k_ids))\n",
    "    print(f\"k= {k}, recall=\", recall(graph_k_ids))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d059d66-245c-446b-a83d-092ffa2bd1fe",
   "metadata": {},
   "source": [
    "Different Similaity thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38456eb5-f184-4df3-8f33-76a113c93738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
